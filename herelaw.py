import streamlit as st
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from langsmith import traceable
from langsmith.wrappers import wrap_openai
from dotenv import load_dotenv
import os

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Herelaw", page_icon="âš–ï¸")
st.title("ğŸš€ Herelaw AI Legal Assistant")

# ì‚¬ìš©ìë¡œë¶€í„° ì§ˆë¬¸ ì…ë ¥ë°›ê¸°
user_question = st.text_area("Enter the details of your legal case:")

# "ì†Œì¥ì„ ì‘ì„±í•´ì¤˜" ë¬¸êµ¬ ì¶”ê°€
user_question_request = user_question + "ì´ ì‚¬ê±´ì— ëŒ€í•´ ë²•ì› ì œì¶œí•  ì†Œì¥ ì´ˆì•ˆì„ ì‘ì„±í•´ì¤˜."

# í…œí”Œë¦¿ ì •ì˜
template = """ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë³€í˜¸ì‚¬ë¡œì„œ {question}ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¼€ì´ìŠ¤ì— ëŒ€í•œ í•­ëª©ì„ ë¶„ë¥˜í•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”"""

# GPT-4o-mini ëª¨ë¸ ìƒì„±
gpt4_mini_llm = ChatOpenAI(
    model_name="gpt-4o-mini",  # GPT-4o-mini ëª¨ë¸
    temperature=0,
    api_key=api_key
)

# íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ìƒì„±
fine_tuned_llm = ChatOpenAI(
    model_name="ft:gpt-4o-mini-2024-07-18:personal::A16MtkYX",  # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ID
    temperature=0,
    api_key=api_key
)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
chat_prompt = PromptTemplate(
    input_variables=["question"],
    template=template
)

# ë‘ ê°œì˜ LLMChain ìƒì„±
gpt4_mini_chain = LLMChain(llm=gpt4_mini_llm, prompt=chat_prompt)
fine_tuned_chain = LLMChain(llm=fine_tuned_llm, prompt=chat_prompt)

# Langsmith Traceable Wrappers
traceable_gpt4_mini = traceable(gpt4_mini_chain)
traceable_fine_tuned = traceable(fine_tuned_chain)

# ë²„íŠ¼ í´ë¦­ ì‹œ ì‘ë‹µ ìƒì„±
if st.button("ì¼€ì´ìŠ¤ ë¶„ì„í•˜ê¸°"):
    if user_question:
        with st.spinner("Analyzing your case..."):
            # ë‘ ëª¨ë¸ë¡œë¶€í„° ë‹µë³€ ë°›ê¸°
            gpt4_mini_response = gpt4_mini_chain.run(question=user_question)
            fine_tuned_response = fine_tuned_chain.run(question=user_question)

            # ì†Œì¥ ì‘ì„± ìš”ì²­ ì²˜ë¦¬
            export_response = gpt4_mini_chain.run(question=user_question_request)

            # ì¢…í•© ë‹µë³€ ìƒì„±
            combined_response = f"**íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì˜ ë‹µë³€:**\n{fine_tuned_response}\n\n" \
                                f"**ì†Œì¥ ì‘ì„±:**\n{export_response}"

            # ê²°ê³¼ ì¶œë ¥
            st.write(combined_response)

    else:
        st.warning("Please enter the details of your legal case.")