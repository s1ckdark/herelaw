import streamlit as st
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai.llms import OpenAI
from dotenv import load_dotenv
import os

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Legal Advisor", page_icon="âš–ï¸")
st.title("ğŸš€ AI Legal Advisor: Get Your Case Evaluated ğŸ—¨ï¸")

# ì‚¬ìš©ìë¡œë¶€í„° ì§ˆë¬¸ ì…ë ¥ë°›ê¸°
user_question = st.text_area("Enter the details of your legal case:")

# í…œí”Œë¦¿ ì •ì˜
template = """ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë³€í˜¸ì‚¬ë¡œì„œ {question}ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¼€ì´ìŠ¤ì— ëŒ€í•œ í•­ëª©ì„ ë¶„ë¥˜í•´ì„œ ë‹µí•´ì£¼ì„¸ìš”"""

# LLM ê°ì²´ ìƒì„±
llm = OpenAI(
    model_name="ft:gpt-4o-mini-2024-07-18:personal::A16MtkYX",  # ëª¨ë¸ëª…
    temperature=0,  # ì°½ì˜ì„± ì¡°ì ˆ
    api_key=api_key
)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
chat_prompt = PromptTemplate(
    input_variables=["question"],
    template=template
)

# LLMChain ìƒì„±
llm_chain = LLMChain(llm=llm, prompt=chat_prompt)

# ë²„íŠ¼ í´ë¦­ ì‹œ ì‘ë‹µ ìƒì„±
if st.button("Get Legal Advice"):
    if user_question:
        with st.spinner("Analyzing your case..."):
            response = llm_chain.run(question=user_question)
            st.write("### AI's Response:")
            st.write(response)
    else:
        st.warning("Please enter the details of your legal case.")
